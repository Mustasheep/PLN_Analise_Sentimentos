{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrbNyovvPsFzdBVIvyYQJH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mustasheep/PLN_Analise_Sentimentos/blob/main/Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook terá a função de preparar os dados para serem utilizados em um projeto de processamento de linguagem natural, presente no mesmo repositório.\n",
        "\n",
        "Será utilizado um conjunto de datasets disponíveis no Kaggle. Por serem cinco extensos arquivos csv, irei baixá-los e concatená-los em um único arquivo, para uma melhor eficácia em meu novo projeto."
      ],
      "metadata": {
        "id": "O4pvE3OSBRrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando bibliotecas"
      ],
      "metadata": {
        "id": "M95z8d_vAMjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ocultando mensagens do sistema\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Importando...\n",
        "import os\n",
        "import pandas as pd\n",
        "import kagglehub"
      ],
      "metadata": {
        "id": "rFYmwpSxAGUK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando versão atual do dataset\n",
        "path = kagglehub.dataset_download(\"inigolopezrioboo/a-tripadvisor-dataset-for-nlp-tasks\")"
      ],
      "metadata": {
        "id": "xmqLWAB7APxK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construindo o caminho do dataset...\n",
        "files = [\n",
        "    \"Barcelona_reviews.csv\",\n",
        "    \"London_reviews.csv\",\n",
        "    \"Madrid_reviews.csv\",\n",
        "    \"New_Delhi_reviews.csv\",\n",
        "    \"New_York_reviews.csv\",\n",
        "]\n",
        "\n",
        "for file in files:\n",
        "    file_path = os.path.join(path, file)\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    df.to_csv(file, index=False)"
      ],
      "metadata": {
        "id": "389UKlHXAeCW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparando os datasets\n",
        "path = '.'\n",
        "\n",
        "csv_files = [\n",
        "    '/content/Barcelona_reviews.csv',\n",
        "    '/content/London_reviews.csv',\n",
        "    '/content/Madrid_reviews.csv',\n",
        "    '/content/New_Delhi_reviews.csv',\n",
        "    '/content/New_York_reviews.csv'\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for file_name in csv_files:\n",
        "    file_path = os.path.join(path, file_name)\n",
        "    df = pd.read_csv(file_path)\n",
        "    dfs.append(df)\n",
        "\n",
        "# Juntando para um único Dataframe\n",
        "df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "0b9slF9aAjhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Quantidades de linhas: {df.shape[0]}\")\n",
        "print(f\"Quantidades de colunas: {df.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBtr2z4YCGAq",
        "outputId": "5ae6acec-12db-40c4-988a-f95a40f518cf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidades de linhas: 510463\n",
            "Quantidades de colunas: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com um pouco mais de 510k de amostras será uma boa quantia para que eu possa prosseguir com um projeto de análise de sentimentos, em PLN."
      ],
      "metadata": {
        "id": "9KiJVPMQCNtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o csv\n",
        "df.to_csv('restaurantes.csv', index=False)"
      ],
      "metadata": {
        "id": "WxyZT2lJBBa4"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}
